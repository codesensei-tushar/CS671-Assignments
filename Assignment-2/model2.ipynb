{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim,nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms \n",
    "from export import load_cifar10_data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Archietechture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        \"\"\"\n",
    "        Denoising Autoencoder for CIFAR-10 images\n",
    "        Args:\n",
    "            latent_dim (int): Dimension of the latent space\n",
    "        \"\"\"\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 16x16\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 8x8\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 4x4\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),   # 16x16\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=2, stride=2),    # 32x32\n",
    "            nn.Sigmoid()  # Output values between [0,1]\n",
    "        )\n",
    "\n",
    "    def add_noise(self, x, noise_factor):\n",
    "        \"\"\"Add Gaussian noise to input images\"\"\"\n",
    "        noise = torch.randn_like(x) * noise_factor\n",
    "        noisy_x = x + noise\n",
    "        return torch.clamp(noisy_x, 0., 1.)\n",
    "    \n",
    "    def forward(self, x, noise_factor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        Args:\n",
    "            x (torch.Tensor): Input images [B, C, H, W]\n",
    "            noise_factor (float): Standard deviation of Gaussian noise\n",
    "        \"\"\"\n",
    "        # Add noise to input\n",
    "        noisy_x = self.add_noise(x, noise_factor)\n",
    "        \n",
    "        # Encode noisy input\n",
    "        latent = self.encoder(noisy_x)\n",
    "        \n",
    "        # Decode to reconstruct original\n",
    "        reconstructed = self.decoder(latent)\n",
    "        \n",
    "        return reconstructed, noisy_x, latent\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent space\"\"\"\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent vectors to images\"\"\"\n",
    "        return self.decoder(z)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, latent_dim=256):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv_op = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 32x32 -> 16x16\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 16x16 -> 8x8\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 8x8 -> 4x4\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(256*4*4, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_op(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=256, out_channels=3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 256*4*4)\n",
    "        self.conv_op = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2), # 4x4 -> 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2), # 8x8 -> 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, out_channels, kernel_size=2, stride=2), # 16x16 -> 32x32\n",
    "            nn.Sigmoid() # Pixel values in range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 256, 4, 4)\n",
    "        x = self.conv_op(x)\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channles=3,latent_dim=256):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        self.encoder=Encoder(in_channles,latent_dim)\n",
    "        self.decoder=Decoder(latent_dim,in_channles)\n",
    "    def forward(self,x):\n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torch.cuda.is_available):\n",
    "    device=\"cuda\"\n",
    "    if device==\"cuda\":\n",
    "        num_workers=torch.cuda.device_count() * 1\n",
    "        print(num_workers)\n",
    "        print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(\"cuda is not availabel\")\n",
    "    device= \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), class_names = load_cifar10_data()\n",
    "\n",
    "print(f\"Training Data: {train_images.shape}, Labels: {train_labels.shape}\")\n",
    "print(f\"Test Data: {test_images.shape}, Labels: {test_labels.shape}\")\n",
    "print(f\"Class Names: {class_names}\")\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10Dataset(train_images, train_labels, transform=transform)\n",
    "test_dataset = CIFAR10Dataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train loader: {train_loader}\")\n",
    "print(f\"Test loader: {test_loader}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_dae(model, dataloader, val_loader, criterion, optimizer, device, noise_factor, n_epochs):\n",
    "    \"\"\"Train for one epoch and track losses\"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(dataloader, desc=f'Training Epoch {epoch+1}/{n_epochs}')\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(pbar):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            reconstructed, noisy_x, _ = model(data, noise_factor)\n",
    "            \n",
    "            # Compute reconstruction loss\n",
    "            loss = criterion(reconstructed, data)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_description(f'Training (loss={loss.item():.4f})')\n",
    "        \n",
    "        train_loss = total_loss / len(dataloader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = evaluate(model, val_loader, criterion, device, noise_factor)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_dae(model, dataloader, criterion, device, noise_factor):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    for batch_idx, (data, _) in enumerate(pbar):\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed, noisy_x, _ = model(data, noise_factor)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        loss = criterion(reconstructed, data)\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_description(f'Evaluating (loss={loss.item():.4f})')\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ae(model, dataloader, criterion, optimizer, device,epochs):\n",
    "    # epochs = 20\n",
    "    outputs = []\n",
    "    losses = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (images, _) in enumerate(dataloader):  # Get images from train_loader\n",
    "            images = images.to(device, dtype=torch.float32)  # Send to GPU/CPU\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Print loss every 100 batches to reduce console clutter\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "    return model, losses\n",
    "\n",
    "def evaluate_ae(model, dataloader, criterion,device):\n",
    "    model.eval()\n",
    "\n",
    "    # Get test images and reconstructed images\n",
    "    test_images, _ = next(iter(dataloader))  # Fetch a batch from test_loader\n",
    "    test_images = test_images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images = model(test_images)\n",
    "\n",
    "    # Convert tensors to numpy for evaluation\n",
    "    test_images_np = test_images.cpu().detach().numpy()\n",
    "    reconstructed_images_np = reconstructed_images.cpu().detach().numpy()\n",
    "\n",
    "    # Function to evaluate reconstruction quality\n",
    "    def evaluate_reconstruction(original, reconstructed):\n",
    "        batch_size = original.shape[0]\n",
    "        ssim_scores, psnr_scores, mae_scores, mse_scores = [], [], [], []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            orig = np.transpose(original[i], (1, 2, 0))  # Convert (C, H, W) → (H, W, C)\n",
    "            recon = np.transpose(reconstructed[i], (1, 2, 0))\n",
    "\n",
    "            ssim_scores.append(ssim(orig, recon, channel_axis=-1, data_range=1.0, win_size=3))\n",
    "            psnr_scores.append(psnr(orig, recon, data_range=1.0))\n",
    "            mae_scores.append(np.mean(np.abs(orig - recon)))\n",
    "            mse_scores.append(np.mean((orig - recon) ** 2))\n",
    "\n",
    "        return {\n",
    "            \"SSIM\": np.mean(ssim_scores),\n",
    "            \"PSNR\": np.mean(psnr_scores),\n",
    "            \"MAE\": np.mean(mae_scores),\n",
    "            \"MSE\": np.mean(mse_scores),\n",
    "        }\n",
    "\n",
    "    # Get the evaluation results\n",
    "    # metrics = evaluate_reconstruction(test_images_np, reconstructed_images_np)\n",
    "    # print(\"Evaluation Results:\", metrics)s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters and model paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "noise_factors = [0.1,0.3,0.5]\n",
    "model_paths = {\n",
    "    'ae': 'Assignment-2/models/autoencoder.pth',\n",
    "    0.1: 'Assignment-2/models/denoising_autoencoder_0.1.pth',\n",
    "    0.3: 'Assignment-2/models/denoising_autoencoder_0.3.pth',\n",
    "    0.5: 'Assignment-2/models/denoising_autoencoder_0.5.pth'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilizing the model \n",
    "### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(in_channles=3,latent_dim=256)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "model, train_loss = train_epoch_ae(model, train_loader, criterion, optimizer, device,n_epochs)\n",
    "val_loss = evaluate_ae(model, test_loader, criterion, device)\n",
    "torch.save(model.state_dict(),'Assignment-2/models/autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilizing the model \n",
    "### denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenoisingAutoencoder(latent_dim=128).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "losses = {}\n",
    "for noise_factor in noise_factors:\n",
    "    print(f\"\\nTraining with noise factor {noise_factor}\")\n",
    "    model, train_losses, val_losses = train_epoch(\n",
    "        model, \n",
    "        train_loader, \n",
    "        test_loader,  # Using test_loader as validation\n",
    "        criterion, \n",
    "        optimizer, \n",
    "        device, \n",
    "        noise_factor,\n",
    "        n_epochs\n",
    "    )\n",
    "\n",
    "    losses[noise_factor] = {\n",
    "        'train': train_losses,\n",
    "        'val': val_losses\n",
    "    }\n",
    " \n",
    "    torch.save(model.state_dict(), f'Assignment-2/models/denoising_autoencoder_{noise_factor}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuvalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(models, test_loader, num_images=8):\n",
    "    \"\"\"Visualize original, noisy and reconstructed images from multiple models\"\"\"\n",
    "    num_models = len(models)\n",
    "    fig, axes = plt.subplots(num_models * 2, num_images, figsize=(20, num_models * 3))\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.15)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images, _ = next(iter(test_loader))\n",
    "        images = images.to(device)\n",
    "\n",
    "        for idx, (model_name, model) in enumerate(models.items()):\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            \n",
    "            # Add row labels on the left\n",
    "            if model_name == 'ae':\n",
    "                fig.text(0.02, 0.73 - (idx * 0.25), 'AutoEncoder', \n",
    "                        fontsize=12, rotation=90, va='center')\n",
    "                reconstructed = model(images)\n",
    "                images_np = images.cpu().numpy()\n",
    "                reconstructed_np = reconstructed.cpu().numpy()\n",
    "            else:\n",
    "                # Extract noise factor from model name (which is now a string)\n",
    "                current_noise = float(model_name)\n",
    "                fig.text(0.02, 0.73 - (idx * 0.25), f'DAE (σ={current_noise})', \n",
    "                        fontsize=12, rotation=90, va='center')\n",
    "                reconstructed, noisy, _ = model(images, current_noise)\n",
    "                noisy_np = noisy.cpu().numpy()\n",
    "                reconstructed_np = reconstructed.cpu().numpy()\n",
    "            \n",
    "            for i in range(num_images):\n",
    "                # Remove axis spines and increase image size\n",
    "                for spine in ['top', 'right', 'bottom', 'left']:\n",
    "                    axes[idx * 2, i].spines[spine].set_visible(False)\n",
    "                    axes[idx * 2 + 1, i].spines[spine].set_visible(False)\n",
    "                \n",
    "                if model_name == 'ae':\n",
    "                    axes[idx * 2, i].imshow(np.transpose(images_np[i], (1, 2, 0)))\n",
    "                else:\n",
    "                    axes[idx * 2, i].imshow(np.transpose(noisy_np[i], (1, 2, 0)))\n",
    "                \n",
    "                axes[idx * 2, i].set_xticks([])\n",
    "                axes[idx * 2, i].set_yticks([])\n",
    "                \n",
    "                axes[idx * 2 + 1, i].imshow(np.transpose(reconstructed_np[i], (1, 2, 0)))\n",
    "                axes[idx * 2 + 1, i].set_xticks([])\n",
    "                axes[idx * 2 + 1, i].set_yticks([])\n",
    "            \n",
    "            # Set titles\n",
    "            if model_name == 'ae':\n",
    "                axes[idx * 2, 0].set_title(\"Original Input\", pad=2, fontsize=10)\n",
    "                axes[idx * 2 + 1, 0].set_title(\"Reconstructed Output\", pad=2, fontsize=10)\n",
    "            else:\n",
    "                axes[idx * 2, 0].set_title(f\"Noisy Input (σ={current_noise})\", pad=2, fontsize=10)\n",
    "                axes[idx * 2 + 1, 0].set_title(\"Denoised Output\", pad=2, fontsize=10)\n",
    "\n",
    "    fig.suptitle('Reconstruction Results: AutoEncoder vs Denoising AutoEncoder', \n",
    "                 fontsize=14, y=0.95)\n",
    "    plt.tight_layout(rect=[0.03, 0, 1, 0.95])\n",
    "    plt.savefig(\"Assignment-2/images/reconstruction_comparison_all.png\", \n",
    "                bbox_inches='tight', dpi=300, pad_inches=0.2)\n",
    "\n",
    "def epoch_vs_loss(losses):\n",
    "    \"\"\"Plot training and validation losses for each noise factor\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for noise_factor, loss in losses.items():\n",
    "        plt.plot(loss['train'], label=f'Train Loss (Noise {noise_factor})')\n",
    "        plt.plot(loss['val'], label=f'Val Loss (Noise {noise_factor})')\n",
    "    \n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"Assignment-2/images/loss_vs_epoch.png\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model for visuvalisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "# losses['ae'] = {'train': train_loss, 'val': val_loss}\n",
    "for name, path in model_paths.items():\n",
    "    model = DenoisingAutoencoder(latent_dim=128).to(device) if name != 'ae' else AutoEncoder(in_channles=3, latent_dim=256).to(device)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    models[str(name)] = model\n",
    "# print(models.items())\n",
    "# Call visualize_reconstruction\n",
    "visualize_reconstruction(models,test_loader=test_loader, num_images=8)\n",
    "epoch_vs_loss(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
